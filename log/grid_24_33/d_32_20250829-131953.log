time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=32, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 67,328 parameters
  ├─ convs: 67,328 parameters
query_linear: 67,584 parameters
  ├─ convs: 67,584 parameters
nav_attention: 397,056 parameters
  ├─ W_q: 66,304 parameters
  ├─ W_k: 66,304 parameters
  ├─ W_v: 66,304 parameters
  ├─ mapping: 66,304 parameters
  ├─ fusion: 131,840 parameters
st_embedding: 283,904 parameters
  ├─ FC_se: 83,456 parameters
  ├─ FC_te: 200,448 parameters
encoder_blocks: 4,611,588 parameters
  ├─ 0: 2,305,794 parameters
  ├─ 1: 2,305,794 parameters
transform_attn: 265,216 parameters
  ├─ FC_q: 66,304 parameters
  ├─ FC_k: 66,304 parameters
  ├─ FC_v: 66,304 parameters
  ├─ FC: 66,304 parameters
decoder_blocks: 4,611,588 parameters
  ├─ 0: 2,305,794 parameters
  ├─ 1: 2,305,794 parameters
output_layer: 66,563 parameters
  ├─ convs: 66,563 parameters
trainable parameters: 10,370,836
**** training model ****
2025-08-27 19:12:00 | epoch: 0001/100, training time: 88.7s, inference time: 3.1s
train loss: 2.8553, val_loss: 2.3547
val loss decrease from inf to 2.3547, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:13:35 | epoch: 0002/100, training time: 92.5s, inference time: 3.0s
train loss: 2.5319, val_loss: 2.1370
val loss decrease from 2.3547 to 2.1370, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:15:09 | epoch: 0003/100, training time: 90.5s, inference time: 3.0s
train loss: 2.4517, val_loss: 2.1601
2025-08-27 19:16:40 | epoch: 0004/100, training time: 88.4s, inference time: 3.0s
train loss: 2.4047, val_loss: 2.1193
val loss decrease from 2.1370 to 2.1193, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:18:10 | epoch: 0005/100, training time: 87.1s, inference time: 3.0s
train loss: 2.4030, val_loss: 2.1111
val loss decrease from 2.1193 to 2.1111, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:19:39 | epoch: 0006/100, training time: 85.5s, inference time: 3.0s
train loss: 2.3813, val_loss: 2.1015
val loss decrease from 2.1111 to 2.1015, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:21:09 | epoch: 0007/100, training time: 87.6s, inference time: 3.0s
train loss: 2.3720, val_loss: 2.1095
2025-08-27 19:22:40 | epoch: 0008/100, training time: 87.3s, inference time: 3.0s
train loss: 2.3627, val_loss: 2.1012
val loss decrease from 2.1015 to 2.1012, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:24:11 | epoch: 0009/100, training time: 88.1s, inference time: 3.0s
train loss: 2.3545, val_loss: 2.1705
2025-08-27 19:25:40 | epoch: 0010/100, training time: 86.1s, inference time: 3.0s
train loss: 2.3418, val_loss: 2.0977
val loss decrease from 2.1012 to 2.0977, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:27:09 | epoch: 0011/100, training time: 86.3s, inference time: 3.0s
train loss: 2.3196, val_loss: 2.0847
val loss decrease from 2.0977 to 2.0847, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:28:39 | epoch: 0012/100, training time: 87.3s, inference time: 3.0s
train loss: 2.3163, val_loss: 2.1032
2025-08-27 19:30:10 | epoch: 0013/100, training time: 87.3s, inference time: 3.0s
train loss: 2.3014, val_loss: 2.0492
val loss decrease from 2.0847 to 2.0492, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:31:39 | epoch: 0014/100, training time: 86.5s, inference time: 3.0s
train loss: 2.2854, val_loss: 2.0655
2025-08-27 19:33:09 | epoch: 0015/100, training time: 86.8s, inference time: 3.0s
train loss: 2.2826, val_loss: 2.0475
val loss decrease from 2.0492 to 2.0475, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:34:38 | epoch: 0016/100, training time: 86.3s, inference time: 3.0s
train loss: 2.2908, val_loss: 2.0620
2025-08-27 19:36:08 | epoch: 0017/100, training time: 86.4s, inference time: 3.0s
train loss: 2.2889, val_loss: 2.0651
2025-08-27 19:37:38 | epoch: 0018/100, training time: 87.0s, inference time: 3.0s
train loss: 2.2787, val_loss: 2.0588
2025-08-27 19:39:08 | epoch: 0019/100, training time: 87.6s, inference time: 3.0s
train loss: 2.2266, val_loss: 2.0457
val loss decrease from 2.0475 to 2.0457, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-27 19:40:40 | epoch: 0020/100, training time: 88.2s, inference time: 3.0s
train loss: 2.2717, val_loss: 2.0626
2025-08-27 19:42:13 | epoch: 0021/100, training time: 90.9s, inference time: 3.0s
train loss: 2.2477, val_loss: 2.0834
2025-08-27 19:43:47 | epoch: 0022/100, training time: 90.6s, inference time: 3.0s
train loss: 2.2634, val_loss: 2.1008
2025-08-27 19:45:17 | epoch: 0023/100, training time: 86.4s, inference time: 3.0s
train loss: 2.2321, val_loss: 2.0973
2025-08-27 19:46:46 | epoch: 0024/100, training time: 86.1s, inference time: 3.0s
train loss: 2.2568, val_loss: 2.1117
2025-08-27 19:48:15 | epoch: 0025/100, training time: 86.5s, inference time: 3.0s
train loss: 2.2085, val_loss: 2.0655
2025-08-27 19:49:45 | epoch: 0026/100, training time: 86.4s, inference time: 3.0s
train loss: 2.1947, val_loss: 2.0735
2025-08-27 19:51:14 | epoch: 0027/100, training time: 86.6s, inference time: 3.0s
train loss: 2.2320, val_loss: 2.0679
2025-08-27 19:52:44 | epoch: 0028/100, training time: 87.1s, inference time: 3.0s
train loss: 2.2295, val_loss: 2.0661
2025-08-27 19:54:14 | epoch: 0029/100, training time: 86.9s, inference time: 3.0s
train loss: 2.2098, val_loss: 2.0835
early stop at epoch: 0029
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8614, RMSE: 2.8961, MAPE: 6.17%
performance in each prediction step (train)
step 1: MAE=1.5437, RMSE=2.3265, MAPE=5.15%
step 2: MAE=1.8704, RMSE=2.9022, MAPE=6.18%
step 3: MAE=1.8969, RMSE=2.9616, MAPE=6.27%
step 4: MAE=1.8943, RMSE=2.9611, MAPE=6.27%
step 5: MAE=1.8962, RMSE=2.9650, MAPE=6.29%
step 6: MAE=1.9064, RMSE=2.9823, MAPE=6.33%
step 7: MAE=1.9266, RMSE=3.0132, MAPE=6.40%
step 8: MAE=1.9564, RMSE=3.0565, MAPE=6.51%
average: MAE=1.8614, RMSE=2.8961, MAPE=6.17%
val MAE: 2.0833, RMSE: 3.2012, MAPE: 6.94%
performance in each prediction step (val)
step 1: MAE=1.6655, RMSE=2.4753, MAPE=5.55%
step 2: MAE=2.0523, RMSE=3.1325, MAPE=6.82%
step 3: MAE=2.1231, RMSE=3.2775, MAPE=7.07%
step 4: MAE=2.1446, RMSE=3.3224, MAPE=7.15%
step 5: MAE=2.1571, RMSE=3.3430, MAPE=7.19%
step 6: MAE=2.1668, RMSE=3.3516, MAPE=7.23%
step 7: MAE=2.1744, RMSE=3.3523, MAPE=7.24%
step 8: MAE=2.1826, RMSE=3.3548, MAPE=7.26%
average: MAE=2.0833, RMSE=3.2012, MAPE=6.94%
test MAE: 2.1756, RMSE: 3.3645, MAPE: 7.19%
performance in each prediction step (test)
step 1: MAE=1.6910, RMSE=2.5017, MAPE=5.63%
step 2: MAE=2.1155, RMSE=3.2314, MAPE=6.97%
step 3: MAE=2.2028, RMSE=3.4116, MAPE=7.26%
step 4: MAE=2.2409, RMSE=3.4868, MAPE=7.38%
step 5: MAE=2.2650, RMSE=3.5314, MAPE=7.47%
step 6: MAE=2.2841, RMSE=3.5640, MAPE=7.55%
step 7: MAE=2.2973, RMSE=3.5845, MAPE=7.60%
step 8: MAE=2.3081, RMSE=3.6044, MAPE=7.64%
average: MAE=2.1756, RMSE=3.3645, MAPE=7.19%
total testing time: 36.4s
total time: 44.8min
