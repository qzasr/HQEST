time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=12, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 9,888 parameters
  ├─ convs: 9,888 parameters
query_linear: 9,984 parameters
  ├─ convs: 9,984 parameters
nav_attention: 56,736 parameters
  ├─ W_q: 9,504 parameters
  ├─ W_k: 9,504 parameters
  ├─ W_v: 9,504 parameters
  ├─ mapping: 9,504 parameters
  ├─ fusion: 18,720 parameters
st_embedding: 45,024 parameters
  ├─ FC_se: 15,936 parameters
  ├─ FC_te: 29,088 parameters
encoder_blocks: 665,828 parameters
  ├─ 0: 332,914 parameters
  ├─ 1: 332,914 parameters
transform_attn: 38,016 parameters
  ├─ FC_q: 9,504 parameters
  ├─ FC_k: 9,504 parameters
  ├─ FC_v: 9,504 parameters
  ├─ FC: 9,504 parameters
decoder_blocks: 665,828 parameters
  ├─ 0: 332,914 parameters
  ├─ 1: 332,914 parameters
output_layer: 9,603 parameters
  ├─ convs: 9,603 parameters
trainable parameters: 1,500,916
**** training model ****
2025-08-26 05:38:14 | epoch: 0001/100, training time: 87.2s, inference time: 3.1s
train loss: 2.8624, val_loss: 2.2960
val loss decrease from inf to 2.2960, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 05:39:47 | epoch: 0002/100, training time: 89.4s, inference time: 3.1s
train loss: 2.5179, val_loss: 2.1634
val loss decrease from 2.2960 to 2.1634, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 05:41:19 | epoch: 0003/100, training time: 89.4s, inference time: 3.1s
train loss: 2.4426, val_loss: 2.1923
2025-08-26 05:42:52 | epoch: 0004/100, training time: 89.6s, inference time: 3.1s
train loss: 2.3940, val_loss: 2.1873
2025-08-26 05:44:23 | epoch: 0005/100, training time: 88.0s, inference time: 3.1s
train loss: 2.3917, val_loss: 2.1310
val loss decrease from 2.1634 to 2.1310, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 05:45:56 | epoch: 0006/100, training time: 89.4s, inference time: 3.1s
train loss: 2.3685, val_loss: 2.1004
val loss decrease from 2.1310 to 2.1004, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 05:47:27 | epoch: 0007/100, training time: 88.5s, inference time: 3.1s
train loss: 2.3583, val_loss: 2.1136
2025-08-26 05:49:00 | epoch: 0008/100, training time: 89.2s, inference time: 3.1s
train loss: 2.3504, val_loss: 2.1337
2025-08-26 05:50:33 | epoch: 0009/100, training time: 90.5s, inference time: 3.2s
train loss: 2.3393, val_loss: 2.1279
2025-08-26 05:52:07 | epoch: 0010/100, training time: 90.1s, inference time: 3.2s
train loss: 2.3357, val_loss: 2.0692
val loss decrease from 2.1004 to 2.0692, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 05:53:39 | epoch: 0011/100, training time: 89.1s, inference time: 3.1s
train loss: 2.3096, val_loss: 2.1629
2025-08-26 05:55:11 | epoch: 0012/100, training time: 89.5s, inference time: 3.1s
train loss: 2.2996, val_loss: 2.0713
2025-08-26 05:56:44 | epoch: 0013/100, training time: 89.7s, inference time: 3.1s
train loss: 2.2859, val_loss: 2.0627
val loss decrease from 2.0692 to 2.0627, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 05:58:17 | epoch: 0014/100, training time: 89.7s, inference time: 3.1s
train loss: 2.2718, val_loss: 2.0699
2025-08-26 05:59:51 | epoch: 0015/100, training time: 91.0s, inference time: 3.3s
train loss: 2.2671, val_loss: 2.0406
val loss decrease from 2.0627 to 2.0406, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 06:01:29 | epoch: 0016/100, training time: 93.8s, inference time: 3.4s
train loss: 2.2765, val_loss: 2.0388
val loss decrease from 2.0406 to 2.0388, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 06:03:06 | epoch: 0017/100, training time: 93.9s, inference time: 3.2s
train loss: 2.2716, val_loss: 2.0787
2025-08-26 06:04:40 | epoch: 0018/100, training time: 90.8s, inference time: 3.1s
train loss: 2.2636, val_loss: 2.0627
2025-08-26 06:06:13 | epoch: 0019/100, training time: 90.7s, inference time: 3.1s
train loss: 2.2176, val_loss: 2.0500
2025-08-26 06:07:46 | epoch: 0020/100, training time: 89.6s, inference time: 3.1s
train loss: 2.2634, val_loss: 2.0514
2025-08-26 06:09:20 | epoch: 0021/100, training time: 90.5s, inference time: 3.1s
train loss: 2.2311, val_loss: 2.0583
2025-08-26 06:10:54 | epoch: 0022/100, training time: 91.4s, inference time: 3.1s
train loss: 2.2447, val_loss: 2.0871
2025-08-26 06:12:36 | epoch: 0023/100, training time: 98.1s, inference time: 3.8s
train loss: 2.2138, val_loss: 2.0659
2025-08-26 06:14:19 | epoch: 0024/100, training time: 98.7s, inference time: 3.9s
train loss: 2.2353, val_loss: 2.1083
2025-08-26 06:15:53 | epoch: 0025/100, training time: 91.0s, inference time: 3.0s
train loss: 2.1910, val_loss: 2.0330
val loss decrease from 2.0388 to 2.0330, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 06:17:27 | epoch: 0026/100, training time: 91.2s, inference time: 3.2s
train loss: 2.1769, val_loss: 2.0515
2025-08-26 06:19:00 | epoch: 0027/100, training time: 89.5s, inference time: 3.1s
train loss: 2.2123, val_loss: 2.0909
2025-08-26 06:20:33 | epoch: 0028/100, training time: 89.7s, inference time: 3.2s
train loss: 2.2165, val_loss: 2.0866
2025-08-26 06:22:06 | epoch: 0029/100, training time: 90.3s, inference time: 3.2s
train loss: 2.2008, val_loss: 2.0769
2025-08-26 06:23:40 | epoch: 0030/100, training time: 90.3s, inference time: 3.1s
train loss: 2.2219, val_loss: 2.6251
2025-08-26 06:25:12 | epoch: 0031/100, training time: 89.5s, inference time: 3.1s
train loss: 2.3361, val_loss: 3.1393
2025-08-26 06:26:43 | epoch: 0032/100, training time: 87.4s, inference time: 3.2s
train loss: 2.2769, val_loss: 3.1868
2025-08-26 06:28:11 | epoch: 0033/100, training time: 85.2s, inference time: 3.1s
train loss: 2.2299, val_loss: 3.3361
2025-08-26 06:29:42 | epoch: 0034/100, training time: 88.0s, inference time: 3.1s
train loss: 2.2367, val_loss: 2.0624
2025-08-26 06:31:15 | epoch: 0035/100, training time: 89.4s, inference time: 3.0s
train loss: 2.1846, val_loss: 2.0781
early stop at epoch: 0035
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8386, RMSE: 2.8057, MAPE: 6.34%
performance in each prediction step (train)
step 1: MAE=1.6122, RMSE=2.3953, MAPE=5.51%
step 2: MAE=1.8740, RMSE=2.8494, MAPE=6.45%
step 3: MAE=1.8777, RMSE=2.8722, MAPE=6.48%
step 4: MAE=1.8628, RMSE=2.8538, MAPE=6.43%
step 5: MAE=1.8562, RMSE=2.8456, MAPE=6.41%
step 6: MAE=1.8581, RMSE=2.8483, MAPE=6.42%
step 7: MAE=1.8701, RMSE=2.8696, MAPE=6.47%
step 8: MAE=1.8977, RMSE=2.9117, MAPE=6.58%
average: MAE=1.8386, RMSE=2.8057, MAPE=6.34%
val MAE: 2.0744, RMSE: 3.1941, MAPE: 7.21%
performance in each prediction step (val)
step 1: MAE=1.7172, RMSE=2.6096, MAPE=5.95%
step 2: MAE=2.0710, RMSE=3.1850, MAPE=7.22%
step 3: MAE=2.1147, RMSE=3.2673, MAPE=7.37%
step 4: MAE=2.1210, RMSE=3.2810, MAPE=7.38%
step 5: MAE=2.1284, RMSE=3.2884, MAPE=7.39%
step 6: MAE=2.1402, RMSE=3.3031, MAPE=7.42%
step 7: MAE=2.1498, RMSE=3.3130, MAPE=7.45%
step 8: MAE=2.1528, RMSE=3.3055, MAPE=7.46%
average: MAE=2.0744, RMSE=3.1941, MAPE=7.21%
test MAE: 2.1207, RMSE: 3.2601, MAPE: 7.30%
performance in each prediction step (test)
step 1: MAE=1.7383, RMSE=2.5915, MAPE=5.98%
step 2: MAE=2.1021, RMSE=3.2266, MAPE=7.25%
step 3: MAE=2.1596, RMSE=3.3346, MAPE=7.45%
step 4: MAE=2.1770, RMSE=3.3663, MAPE=7.50%
step 5: MAE=2.1899, RMSE=3.3860, MAPE=7.54%
step 6: MAE=2.1965, RMSE=3.3928, MAPE=7.56%
step 7: MAE=2.2005, RMSE=3.3911, MAPE=7.57%
step 8: MAE=2.2020, RMSE=3.3919, MAPE=7.58%
average: MAE=2.1207, RMSE=3.2601, MAPE=7.30%
total testing time: 32.0s
total time: 55.5min
