time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=2, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 4,544 parameters
  ├─ convs: 4,544 parameters
query_linear: 4,608 parameters
  ├─ convs: 4,608 parameters
nav_attention: 25,536 parameters
  ├─ W_q: 4,288 parameters
  ├─ W_k: 4,288 parameters
  ├─ W_v: 4,288 parameters
  ├─ mapping: 4,288 parameters
  ├─ fusion: 8,384 parameters
st_embedding: 21,824 parameters
  ├─ FC_se: 8,576 parameters
  ├─ FC_te: 13,248 parameters
encoder_blocks: 302,148 parameters
  ├─ 0: 151,074 parameters
  ├─ 1: 151,074 parameters
transform_attn: 17,152 parameters
  ├─ FC_q: 4,288 parameters
  ├─ FC_k: 4,288 parameters
  ├─ FC_v: 4,288 parameters
  ├─ FC: 4,288 parameters
decoder_blocks: 302,148 parameters
  ├─ 0: 151,074 parameters
  ├─ 1: 151,074 parameters
output_layer: 4,355 parameters
  ├─ convs: 4,355 parameters
trainable parameters: 682,324
**** training model ****
2025-08-29 13:45:00 | epoch: 0001/100, training time: 345.9s, inference time: 11.7s
train loss: 3.4870, val_loss: 5.0333
val loss decrease from inf to 5.0333, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 13:51:16 | epoch: 0002/100, training time: 362.4s, inference time: 14.2s
train loss: 3.3021, val_loss: 4.0040
val loss decrease from 5.0333 to 4.0040, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 13:57:37 | epoch: 0003/100, training time: 368.5s, inference time: 11.7s
train loss: 3.2105, val_loss: 4.3224
2025-08-29 14:03:45 | epoch: 0004/100, training time: 357.0s, inference time: 11.7s
train loss: 3.2054, val_loss: 4.2559
2025-08-29 14:09:52 | epoch: 0005/100, training time: 354.7s, inference time: 12.1s
train loss: 3.1810, val_loss: 3.6864
val loss decrease from 4.0040 to 3.6864, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 14:16:13 | epoch: 0006/100, training time: 369.8s, inference time: 11.7s
train loss: 3.1443, val_loss: 4.0184
2025-08-29 14:22:21 | epoch: 0007/100, training time: 355.4s, inference time: 11.7s
train loss: 3.1557, val_loss: 4.2707
2025-08-29 14:28:26 | epoch: 0008/100, training time: 353.7s, inference time: 11.7s
train loss: 3.1329, val_loss: 4.0313
2025-08-29 14:34:32 | epoch: 0009/100, training time: 354.2s, inference time: 11.7s
train loss: 3.1535, val_loss: 3.8886
2025-08-29 14:40:36 | epoch: 0010/100, training time: 352.6s, inference time: 11.7s
train loss: 3.1623, val_loss: 3.8216
2025-08-29 14:46:39 | epoch: 0011/100, training time: 351.4s, inference time: 11.7s
train loss: 3.1026, val_loss: 3.8928
2025-08-29 14:52:42 | epoch: 0012/100, training time: 350.8s, inference time: 11.7s
train loss: 3.1158, val_loss: 4.5545
2025-08-29 14:58:44 | epoch: 0013/100, training time: 350.3s, inference time: 11.7s
train loss: 3.1124, val_loss: 3.5736
val loss decrease from 3.6864 to 3.5736, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 15:04:46 | epoch: 0014/100, training time: 350.9s, inference time: 11.7s
train loss: 3.0741, val_loss: 4.0896
2025-08-29 15:10:48 | epoch: 0015/100, training time: 350.0s, inference time: 11.8s
train loss: 3.1324, val_loss: 3.8204
2025-08-29 15:16:49 | epoch: 0016/100, training time: 349.1s, inference time: 11.4s
train loss: 3.0797, val_loss: 4.1163
2025-08-29 15:22:49 | epoch: 0017/100, training time: 348.4s, inference time: 11.7s
train loss: 3.1055, val_loss: 3.6598
2025-08-29 15:28:47 | epoch: 0018/100, training time: 347.1s, inference time: 11.3s
train loss: 3.0897, val_loss: 3.5602
val loss decrease from 3.5736 to 3.5602, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 15:34:52 | epoch: 0019/100, training time: 352.9s, inference time: 11.7s
train loss: 3.0596, val_loss: 3.3127
val loss decrease from 3.5602 to 3.3127, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 15:40:55 | epoch: 0020/100, training time: 351.1s, inference time: 11.7s
train loss: 3.0806, val_loss: 3.4711
2025-08-29 15:46:58 | epoch: 0021/100, training time: 351.2s, inference time: 11.8s
train loss: 3.0472, val_loss: 4.0222
2025-08-29 15:53:02 | epoch: 0022/100, training time: 352.6s, inference time: 11.8s
train loss: 3.0750, val_loss: 3.6414
2025-08-29 15:59:04 | epoch: 0023/100, training time: 350.0s, inference time: 11.7s
train loss: 3.0759, val_loss: 3.7359
2025-08-29 16:05:07 | epoch: 0024/100, training time: 352.2s, inference time: 11.7s
train loss: 3.0557, val_loss: 3.5244
2025-08-29 16:11:11 | epoch: 0025/100, training time: 351.8s, inference time: 11.7s
train loss: 3.0456, val_loss: 3.8707
2025-08-29 16:17:18 | epoch: 0026/100, training time: 355.5s, inference time: 11.7s
train loss: 3.0579, val_loss: 3.6425
2025-08-29 16:23:18 | epoch: 0027/100, training time: 348.8s, inference time: 11.4s
train loss: 3.0943, val_loss: 2.4828
val loss decrease from 3.3127 to 2.4828, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 16:29:20 | epoch: 0028/100, training time: 349.4s, inference time: 11.8s
train loss: 3.1219, val_loss: 2.2568
val loss decrease from 2.4828 to 2.2568, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 16:35:19 | epoch: 0029/100, training time: 348.2s, inference time: 11.4s
train loss: 3.0784, val_loss: 2.1718
val loss decrease from 2.2568 to 2.1718, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 16:41:00 | epoch: 0030/100, training time: 329.9s, inference time: 11.5s
train loss: 3.0939, val_loss: 2.2282
2025-08-29 16:47:04 | epoch: 0031/100, training time: 351.6s, inference time: 11.7s
train loss: 3.0974, val_loss: 2.1443
val loss decrease from 2.1718 to 2.1443, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 16:52:51 | epoch: 0032/100, training time: 335.7s, inference time: 11.6s
train loss: 3.0686, val_loss: 2.2432
2025-08-29 16:58:51 | epoch: 0033/100, training time: 347.9s, inference time: 11.7s
train loss: 3.0782, val_loss: 2.3945
2025-08-29 17:04:54 | epoch: 0034/100, training time: 351.1s, inference time: 11.7s
train loss: 3.0417, val_loss: 2.2399
2025-08-29 17:10:54 | epoch: 0035/100, training time: 348.4s, inference time: 11.8s
train loss: 3.0288, val_loss: 2.2884
2025-08-29 17:16:59 | epoch: 0036/100, training time: 353.1s, inference time: 11.7s
train loss: 3.0206, val_loss: 2.2042
2025-08-29 17:22:58 | epoch: 0037/100, training time: 347.9s, inference time: 11.3s
train loss: 3.0793, val_loss: 3.7248
2025-08-29 17:28:54 | epoch: 0038/100, training time: 345.0s, inference time: 11.3s
train loss: 3.0350, val_loss: 3.2446
2025-08-29 17:34:49 | epoch: 0039/100, training time: 343.5s, inference time: 11.4s
train loss: 3.0599, val_loss: 3.3823
2025-08-29 17:40:44 | epoch: 0040/100, training time: 343.7s, inference time: 11.3s
train loss: 3.0501, val_loss: 2.2045
2025-08-29 17:46:34 | epoch: 0041/100, training time: 338.1s, inference time: 11.6s
train loss: 3.0091, val_loss: 2.1941
early stop at epoch: 0041
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 2.0593, RMSE: 3.1486, MAPE: 6.95%
performance in each prediction step (train)
step 1: MAE=1.7280, RMSE=2.5875, MAPE=5.79%
step 2: MAE=2.0456, RMSE=3.1015, MAPE=6.87%
step 3: MAE=2.0867, RMSE=3.1755, MAPE=7.03%
step 4: MAE=2.0904, RMSE=3.1923, MAPE=7.06%
step 5: MAE=2.0982, RMSE=3.2149, MAPE=7.10%
step 6: MAE=2.1136, RMSE=3.2495, MAPE=7.16%
step 7: MAE=2.1369, RMSE=3.2989, MAPE=7.25%
step 8: MAE=2.1748, RMSE=3.3691, MAPE=7.37%
average: MAE=2.0593, RMSE=3.1486, MAPE=6.95%
val MAE: 2.1954, RMSE: 3.3359, MAPE: 7.35%
performance in each prediction step (val)
step 1: MAE=1.7978, RMSE=2.6594, MAPE=5.95%
step 2: MAE=2.1593, RMSE=3.2344, MAPE=7.20%
step 3: MAE=2.2319, RMSE=3.3676, MAPE=7.48%
step 4: MAE=2.2484, RMSE=3.4169, MAPE=7.55%
step 5: MAE=2.2603, RMSE=3.4557, MAPE=7.60%
step 6: MAE=2.2755, RMSE=3.4915, MAPE=7.64%
step 7: MAE=2.2865, RMSE=3.5162, MAPE=7.67%
step 8: MAE=2.3038, RMSE=3.5459, MAPE=7.72%
average: MAE=2.1954, RMSE=3.3359, MAPE=7.35%
test MAE: 2.2533, RMSE: 3.4010, MAPE: 7.48%
performance in each prediction step (test)
step 1: MAE=1.8454, RMSE=2.6928, MAPE=6.08%
step 2: MAE=2.2180, RMSE=3.3141, MAPE=7.33%
step 3: MAE=2.2838, RMSE=3.4381, MAPE=7.56%
step 4: MAE=2.3036, RMSE=3.4796, MAPE=7.64%
step 5: MAE=2.3178, RMSE=3.5157, MAPE=7.71%
step 6: MAE=2.3321, RMSE=3.5493, MAPE=7.77%
step 7: MAE=2.3507, RMSE=3.5859, MAPE=7.84%
step 8: MAE=2.3753, RMSE=3.6326, MAPE=7.92%
average: MAE=2.2533, RMSE=3.4010, MAPE=7.48%
total testing time: 116.3s
total time: 249.9min
