time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=2, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 368 parameters
  ├─ convs: 368 parameters
query_linear: 384 parameters
  ├─ convs: 384 parameters
nav_attention: 1,776 parameters
  ├─ W_q: 304 parameters
  ├─ W_k: 304 parameters
  ├─ W_v: 304 parameters
  ├─ mapping: 304 parameters
  ├─ fusion: 560 parameters
st_embedding: 2,384 parameters
  ├─ FC_se: 1,376 parameters
  ├─ FC_te: 1,008 parameters
encoder_blocks: 22,548 parameters
  ├─ 0: 11,274 parameters
  ├─ 1: 11,274 parameters
transform_attn: 1,216 parameters
  ├─ FC_q: 304 parameters
  ├─ FC_k: 304 parameters
  ├─ FC_v: 304 parameters
  ├─ FC: 304 parameters
decoder_blocks: 22,548 parameters
  ├─ 0: 11,274 parameters
  ├─ 1: 11,274 parameters
output_layer: 323 parameters
  ├─ convs: 323 parameters
trainable parameters: 51,556
**** training model ****
2025-08-26 03:46:42 | epoch: 0001/100, training time: 86.8s, inference time: 3.1s
train loss: 2.8879, val_loss: 2.2743
val loss decrease from inf to 2.2743, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 03:48:13 | epoch: 0002/100, training time: 88.1s, inference time: 3.1s
train loss: 2.5240, val_loss: 2.1656
val loss decrease from 2.2743 to 2.1656, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 03:49:45 | epoch: 0003/100, training time: 88.7s, inference time: 3.1s
train loss: 2.4461, val_loss: 2.2637
2025-08-26 03:51:17 | epoch: 0004/100, training time: 88.6s, inference time: 3.1s
train loss: 2.3954, val_loss: 2.1587
val loss decrease from 2.1656 to 2.1587, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 03:52:48 | epoch: 0005/100, training time: 87.5s, inference time: 3.1s
train loss: 2.3897, val_loss: 2.1144
val loss decrease from 2.1587 to 2.1144, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 03:54:16 | epoch: 0006/100, training time: 85.1s, inference time: 3.1s
train loss: 2.3691, val_loss: 2.0710
val loss decrease from 2.1144 to 2.0710, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 03:55:46 | epoch: 0007/100, training time: 87.3s, inference time: 3.0s
train loss: 2.3580, val_loss: 2.1699
2025-08-26 03:57:16 | epoch: 0008/100, training time: 86.6s, inference time: 3.0s
train loss: 2.3507, val_loss: 2.2074
2025-08-26 03:58:46 | epoch: 0009/100, training time: 87.5s, inference time: 3.0s
train loss: 2.3384, val_loss: 2.1223
2025-08-26 04:00:16 | epoch: 0010/100, training time: 86.9s, inference time: 3.0s
train loss: 2.3329, val_loss: 2.0772
2025-08-26 04:01:46 | epoch: 0011/100, training time: 86.6s, inference time: 3.0s
train loss: 2.3063, val_loss: 2.1531
2025-08-26 04:03:17 | epoch: 0012/100, training time: 88.6s, inference time: 3.0s
train loss: 2.2976, val_loss: 2.0716
2025-08-26 04:04:47 | epoch: 0013/100, training time: 86.9s, inference time: 3.0s
train loss: 2.2789, val_loss: 2.0790
2025-08-26 04:06:18 | epoch: 0014/100, training time: 87.5s, inference time: 3.0s
train loss: 2.2649, val_loss: 2.0615
val loss decrease from 2.0710 to 2.0615, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 04:07:49 | epoch: 0015/100, training time: 87.9s, inference time: 3.0s
train loss: 2.2639, val_loss: 2.0729
2025-08-26 04:09:19 | epoch: 0016/100, training time: 87.6s, inference time: 3.0s
train loss: 2.2701, val_loss: 2.0419
val loss decrease from 2.0615 to 2.0419, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 04:10:49 | epoch: 0017/100, training time: 86.9s, inference time: 3.0s
train loss: 2.2687, val_loss: 2.0855
2025-08-26 04:12:21 | epoch: 0018/100, training time: 88.2s, inference time: 3.1s
train loss: 2.2587, val_loss: 2.0579
2025-08-26 04:13:52 | epoch: 0019/100, training time: 88.1s, inference time: 3.1s
train loss: 2.2143, val_loss: 2.0513
2025-08-26 04:15:23 | epoch: 0020/100, training time: 88.2s, inference time: 3.1s
train loss: 2.2597, val_loss: 2.0634
2025-08-26 04:16:55 | epoch: 0021/100, training time: 88.3s, inference time: 3.1s
train loss: 2.2269, val_loss: 2.0949
2025-08-26 04:18:26 | epoch: 0022/100, training time: 88.7s, inference time: 3.1s
train loss: 2.2400, val_loss: 2.0642
2025-08-26 04:19:57 | epoch: 0023/100, training time: 87.9s, inference time: 3.1s
train loss: 2.2089, val_loss: 2.0550
2025-08-26 04:21:29 | epoch: 0024/100, training time: 88.5s, inference time: 3.1s
train loss: 2.2328, val_loss: 2.0592
2025-08-26 04:23:01 | epoch: 0025/100, training time: 88.3s, inference time: 3.1s
train loss: 2.1873, val_loss: 2.0382
val loss decrease from 2.0419 to 2.0382, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-26 04:24:32 | epoch: 0026/100, training time: 88.4s, inference time: 3.1s
train loss: 2.1763, val_loss: 2.2350
2025-08-26 04:26:02 | epoch: 0027/100, training time: 86.9s, inference time: 3.1s
train loss: 2.2122, val_loss: 2.0744
2025-08-26 04:27:34 | epoch: 0028/100, training time: 88.8s, inference time: 3.1s
train loss: 2.2113, val_loss: 2.0538
2025-08-26 04:29:04 | epoch: 0029/100, training time: 86.9s, inference time: 3.1s
train loss: 2.1983, val_loss: 2.0876
2025-08-26 04:30:34 | epoch: 0030/100, training time: 86.7s, inference time: 3.1s
train loss: 2.1942, val_loss: 2.0774
2025-08-26 04:32:06 | epoch: 0031/100, training time: 89.2s, inference time: 3.1s
train loss: 2.1910, val_loss: 2.0416
2025-08-26 04:33:38 | epoch: 0032/100, training time: 88.4s, inference time: 3.1s
train loss: 2.2039, val_loss: 2.0636
2025-08-26 04:35:09 | epoch: 0033/100, training time: 88.3s, inference time: 3.1s
train loss: 2.1695, val_loss: 2.1295
2025-08-26 04:36:41 | epoch: 0034/100, training time: 88.9s, inference time: 3.1s
train loss: 2.1503, val_loss: 2.0523
2025-08-26 04:38:13 | epoch: 0035/100, training time: 89.0s, inference time: 3.1s
train loss: 2.1488, val_loss: 2.0663
early stop at epoch: 0035
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.7930, RMSE: 2.7356, MAPE: 6.18%
performance in each prediction step (train)
step 1: MAE=1.5518, RMSE=2.2942, MAPE=5.37%
step 2: MAE=1.8202, RMSE=2.7633, MAPE=6.27%
step 3: MAE=1.8241, RMSE=2.7868, MAPE=6.28%
step 4: MAE=1.8137, RMSE=2.7757, MAPE=6.24%
step 5: MAE=1.8118, RMSE=2.7759, MAPE=6.24%
step 6: MAE=1.8180, RMSE=2.7905, MAPE=6.26%
step 7: MAE=1.8350, RMSE=2.8213, MAPE=6.33%
step 8: MAE=1.8695, RMSE=2.8774, MAPE=6.46%
average: MAE=1.7930, RMSE=2.7356, MAPE=6.18%
val MAE: 2.0670, RMSE: 3.1502, MAPE: 7.16%
performance in each prediction step (val)
step 1: MAE=1.6879, RMSE=2.4727, MAPE=5.87%
step 2: MAE=2.0546, RMSE=3.0881, MAPE=7.13%
step 3: MAE=2.1101, RMSE=3.2158, MAPE=7.32%
step 4: MAE=2.1270, RMSE=3.2643, MAPE=7.38%
step 5: MAE=2.1339, RMSE=3.2805, MAPE=7.39%
step 6: MAE=2.1395, RMSE=3.2891, MAPE=7.40%
step 7: MAE=2.1406, RMSE=3.2917, MAPE=7.39%
step 8: MAE=2.1423, RMSE=3.2996, MAPE=7.39%
average: MAE=2.0670, RMSE=3.1502, MAPE=7.16%
test MAE: 2.1179, RMSE: 3.2313, MAPE: 7.32%
performance in each prediction step (test)
step 1: MAE=1.7132, RMSE=2.5020, MAPE=5.94%
step 2: MAE=2.0858, RMSE=3.1477, MAPE=7.22%
step 3: MAE=2.1484, RMSE=3.2832, MAPE=7.43%
step 4: MAE=2.1732, RMSE=3.3314, MAPE=7.51%
step 5: MAE=2.1886, RMSE=3.3605, MAPE=7.55%
step 6: MAE=2.2005, RMSE=3.3873, MAPE=7.59%
step 7: MAE=2.2128, RMSE=3.4107, MAPE=7.63%
step 8: MAE=2.2206, RMSE=3.4277, MAPE=7.66%
average: MAE=2.1179, RMSE=3.2313, MAPE=7.32%
total testing time: 31.1s
total time: 54.0min
