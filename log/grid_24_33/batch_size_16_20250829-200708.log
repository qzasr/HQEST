time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=16, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 4,544 parameters
  ├─ convs: 4,544 parameters
query_linear: 4,608 parameters
  ├─ convs: 4,608 parameters
nav_attention: 25,536 parameters
  ├─ W_q: 4,288 parameters
  ├─ W_k: 4,288 parameters
  ├─ W_v: 4,288 parameters
  ├─ mapping: 4,288 parameters
  ├─ fusion: 8,384 parameters
st_embedding: 21,824 parameters
  ├─ FC_se: 8,576 parameters
  ├─ FC_te: 13,248 parameters
encoder_blocks: 302,148 parameters
  ├─ 0: 151,074 parameters
  ├─ 1: 151,074 parameters
transform_attn: 17,152 parameters
  ├─ FC_q: 4,288 parameters
  ├─ FC_k: 4,288 parameters
  ├─ FC_v: 4,288 parameters
  ├─ FC: 4,288 parameters
decoder_blocks: 302,148 parameters
  ├─ 0: 151,074 parameters
  ├─ 1: 151,074 parameters
output_layer: 4,355 parameters
  ├─ convs: 4,355 parameters
trainable parameters: 682,324
**** training model ****
2025-08-29 20:09:01 | epoch: 0001/100, training time: 79.3s, inference time: 2.6s
train loss: 2.7934, val_loss: 2.3387
val loss decrease from inf to 2.3387, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:10:23 | epoch: 0002/100, training time: 79.5s, inference time: 2.6s
train loss: 2.3745, val_loss: 2.1436
val loss decrease from 2.3387 to 2.1436, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:11:46 | epoch: 0003/100, training time: 80.1s, inference time: 2.6s
train loss: 2.3036, val_loss: 2.1397
val loss decrease from 2.1436 to 2.1397, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:13:09 | epoch: 0004/100, training time: 80.3s, inference time: 2.6s
train loss: 2.2630, val_loss: 2.1404
2025-08-29 20:14:32 | epoch: 0005/100, training time: 80.1s, inference time: 2.6s
train loss: 2.2347, val_loss: 2.1065
val loss decrease from 2.1397 to 2.1065, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:15:54 | epoch: 0006/100, training time: 80.1s, inference time: 2.6s
train loss: 2.2142, val_loss: 2.0524
val loss decrease from 2.1065 to 2.0524, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:17:17 | epoch: 0007/100, training time: 80.1s, inference time: 2.6s
train loss: 2.2195, val_loss: 2.0542
2025-08-29 20:18:40 | epoch: 0008/100, training time: 80.0s, inference time: 2.6s
train loss: 2.1801, val_loss: 2.1321
2025-08-29 20:20:03 | epoch: 0009/100, training time: 80.6s, inference time: 2.6s
train loss: 2.1699, val_loss: 2.0811
2025-08-29 20:21:25 | epoch: 0010/100, training time: 80.0s, inference time: 2.6s
train loss: 2.1616, val_loss: 2.1213
2025-08-29 20:22:49 | epoch: 0011/100, training time: 80.7s, inference time: 2.6s
train loss: 2.1570, val_loss: 2.1463
2025-08-29 20:24:11 | epoch: 0012/100, training time: 80.1s, inference time: 2.6s
train loss: 2.1211, val_loss: 2.1088
2025-08-29 20:25:34 | epoch: 0013/100, training time: 80.4s, inference time: 2.6s
train loss: 2.1544, val_loss: 2.0728
2025-08-29 20:26:57 | epoch: 0014/100, training time: 80.0s, inference time: 2.6s
train loss: 2.1252, val_loss: 2.0445
val loss decrease from 2.0524 to 2.0445, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:28:20 | epoch: 0015/100, training time: 80.0s, inference time: 2.6s
train loss: 2.1158, val_loss: 2.0871
2025-08-29 20:29:42 | epoch: 0016/100, training time: 80.0s, inference time: 2.6s
train loss: 2.1358, val_loss: 2.0604
2025-08-29 20:31:05 | epoch: 0017/100, training time: 80.1s, inference time: 2.6s
train loss: 2.1007, val_loss: 2.0846
2025-08-29 20:32:27 | epoch: 0018/100, training time: 80.0s, inference time: 2.6s
train loss: 2.0775, val_loss: 2.0870
2025-08-29 20:33:50 | epoch: 0019/100, training time: 80.1s, inference time: 2.6s
train loss: 2.0774, val_loss: 2.0347
val loss decrease from 2.0445 to 2.0347, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 20:35:13 | epoch: 0020/100, training time: 80.1s, inference time: 2.6s
train loss: 2.0863, val_loss: 2.0738
2025-08-29 20:36:35 | epoch: 0021/100, training time: 80.1s, inference time: 2.6s
train loss: 2.0870, val_loss: 2.2344
2025-08-29 20:37:58 | epoch: 0022/100, training time: 80.0s, inference time: 2.6s
train loss: 2.0618, val_loss: 2.1510
2025-08-29 20:39:21 | epoch: 0023/100, training time: 80.0s, inference time: 2.6s
train loss: 2.0717, val_loss: 2.0855
2025-08-29 20:40:43 | epoch: 0024/100, training time: 80.0s, inference time: 2.6s
train loss: 2.0983, val_loss: 2.1362
2025-08-29 20:42:06 | epoch: 0025/100, training time: 80.1s, inference time: 2.6s
train loss: 2.0492, val_loss: 2.0792
2025-08-29 20:43:29 | epoch: 0026/100, training time: 80.0s, inference time: 2.6s
train loss: 2.0189, val_loss: 2.0603
2025-08-29 20:44:51 | epoch: 0027/100, training time: 80.1s, inference time: 2.6s
train loss: 2.0499, val_loss: 2.0894
2025-08-29 20:46:14 | epoch: 0028/100, training time: 80.0s, inference time: 2.6s
train loss: 2.0522, val_loss: 2.0827
2025-08-29 20:47:37 | epoch: 0029/100, training time: 80.1s, inference time: 2.6s
train loss: 2.0367, val_loss: 2.1803
early stop at epoch: 0029
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.9295, RMSE: 2.9376, MAPE: 6.54%
performance in each prediction step (train)
step 1: MAE=1.6208, RMSE=2.4495, MAPE=5.58%
step 2: MAE=1.9141, RMSE=2.9179, MAPE=6.50%
step 3: MAE=1.9475, RMSE=2.9722, MAPE=6.59%
step 4: MAE=1.9551, RMSE=2.9845, MAPE=6.61%
step 5: MAE=1.9664, RMSE=3.0006, MAPE=6.64%
step 6: MAE=1.9838, RMSE=3.0223, MAPE=6.70%
step 7: MAE=2.0068, RMSE=3.0533, MAPE=6.78%
step 8: MAE=2.0411, RMSE=3.1004, MAPE=6.90%
average: MAE=1.9295, RMSE=2.9376, MAPE=6.54%
val MAE: 2.1795, RMSE: 3.3148, MAPE: 7.37%
performance in each prediction step (val)
step 1: MAE=1.8016, RMSE=2.7255, MAPE=6.19%
step 2: MAE=2.1512, RMSE=3.2624, MAPE=7.30%
step 3: MAE=2.2144, RMSE=3.3699, MAPE=7.49%
step 4: MAE=2.2353, RMSE=3.4076, MAPE=7.55%
step 5: MAE=2.2447, RMSE=3.4274, MAPE=7.57%
step 6: MAE=2.2553, RMSE=3.4388, MAPE=7.59%
step 7: MAE=2.2623, RMSE=3.4416, MAPE=7.61%
step 8: MAE=2.2711, RMSE=3.4456, MAPE=7.63%
average: MAE=2.1795, RMSE=3.3148, MAPE=7.37%
test MAE: 2.3135, RMSE: 3.5130, MAPE: 7.75%
performance in each prediction step (test)
step 1: MAE=1.9094, RMSE=2.8906, MAPE=6.56%
step 2: MAE=2.2850, RMSE=3.4726, MAPE=7.69%
step 3: MAE=2.3484, RMSE=3.5701, MAPE=7.87%
step 4: MAE=2.3665, RMSE=3.6018, MAPE=7.91%
step 5: MAE=2.3848, RMSE=3.6267, MAPE=7.96%
step 6: MAE=2.3977, RMSE=3.6421, MAPE=8.00%
step 7: MAE=2.4028, RMSE=3.6454, MAPE=8.00%
step 8: MAE=2.4135, RMSE=3.6547, MAPE=8.04%
average: MAE=2.3135, RMSE=3.5130, MAPE=7.75%
total testing time: 26.6s
total time: 40.9min
