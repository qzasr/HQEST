time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/node2vec_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 4,544 parameters
  ├─ convs: 4,544 parameters
query_linear: 4,608 parameters
  ├─ convs: 4,608 parameters
nav_attention: 25,536 parameters
  ├─ W_q: 4,288 parameters
  ├─ W_k: 4,288 parameters
  ├─ W_v: 4,288 parameters
  ├─ mapping: 4,288 parameters
  ├─ fusion: 8,384 parameters
st_embedding: 21,824 parameters
  ├─ FC_se: 8,576 parameters
  ├─ FC_te: 13,248 parameters
encoder_blocks: 302,148 parameters
  ├─ 0: 151,074 parameters
  ├─ 1: 151,074 parameters
transform_attn: 17,152 parameters
  ├─ FC_q: 4,288 parameters
  ├─ FC_k: 4,288 parameters
  ├─ FC_v: 4,288 parameters
  ├─ FC: 4,288 parameters
decoder_blocks: 302,148 parameters
  ├─ 0: 151,074 parameters
  ├─ 1: 151,074 parameters
output_layer: 4,355 parameters
  ├─ convs: 4,355 parameters
trainable parameters: 682,324
**** training model ****
2025-10-17 03:17:13 | epoch: 0001/100, training time: 76.5s, inference time: 2.4s
train loss: 2.8498, val_loss: 2.2298
val loss decrease from inf to 2.2298, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:18:34 | epoch: 0002/100, training time: 78.9s, inference time: 2.3s
train loss: 2.5354, val_loss: 2.1843
val loss decrease from 2.2298 to 2.1843, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:19:55 | epoch: 0003/100, training time: 78.5s, inference time: 2.2s
train loss: 2.4634, val_loss: 2.2839
2025-10-17 03:21:17 | epoch: 0004/100, training time: 80.0s, inference time: 2.7s
train loss: 2.4139, val_loss: 2.1347
val loss decrease from 2.1843 to 2.1347, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:22:40 | epoch: 0005/100, training time: 80.3s, inference time: 2.2s
train loss: 2.4148, val_loss: 2.1742
2025-10-17 03:23:56 | epoch: 0006/100, training time: 74.3s, inference time: 2.2s
train loss: 2.3922, val_loss: 2.1348
2025-10-17 03:25:17 | epoch: 0007/100, training time: 78.0s, inference time: 2.2s
train loss: 2.3777, val_loss: 2.1132
val loss decrease from 2.1347 to 2.1132, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:26:38 | epoch: 0008/100, training time: 78.9s, inference time: 2.4s
train loss: 2.3704, val_loss: 2.1460
2025-10-17 03:27:57 | epoch: 0009/100, training time: 76.7s, inference time: 2.3s
train loss: 2.3603, val_loss: 2.3030
2025-10-17 03:29:16 | epoch: 0010/100, training time: 76.7s, inference time: 2.3s
train loss: 2.3558, val_loss: 2.1436
2025-10-17 03:30:36 | epoch: 0011/100, training time: 77.4s, inference time: 2.3s
train loss: 2.3358, val_loss: 2.1084
val loss decrease from 2.1132 to 2.1084, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:31:55 | epoch: 0012/100, training time: 77.4s, inference time: 2.2s
train loss: 2.3271, val_loss: 2.1161
2025-10-17 03:33:11 | epoch: 0013/100, training time: 73.5s, inference time: 2.1s
train loss: 2.3129, val_loss: 2.0739
val loss decrease from 2.1084 to 2.0739, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:34:27 | epoch: 0014/100, training time: 73.5s, inference time: 2.3s
train loss: 2.2991, val_loss: 2.0899
2025-10-17 03:35:45 | epoch: 0015/100, training time: 76.6s, inference time: 2.2s
train loss: 2.2909, val_loss: 2.0854
2025-10-17 03:37:05 | epoch: 0016/100, training time: 77.5s, inference time: 2.2s
train loss: 2.3033, val_loss: 2.1015
2025-10-17 03:38:26 | epoch: 0017/100, training time: 78.3s, inference time: 2.2s
train loss: 2.2921, val_loss: 2.1230
2025-10-17 03:39:44 | epoch: 0018/100, training time: 76.6s, inference time: 2.2s
train loss: 2.2775, val_loss: 2.0743
2025-10-17 03:41:05 | epoch: 0019/100, training time: 78.7s, inference time: 2.2s
train loss: 2.2336, val_loss: 2.0460
val loss decrease from 2.0739 to 2.0460, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:42:24 | epoch: 0020/100, training time: 76.5s, inference time: 2.3s
train loss: 2.2799, val_loss: 2.0814
2025-10-17 03:43:44 | epoch: 0021/100, training time: 77.8s, inference time: 2.3s
train loss: 2.2574, val_loss: 2.0817
2025-10-17 03:45:06 | epoch: 0022/100, training time: 79.1s, inference time: 2.3s
train loss: 2.2712, val_loss: 2.1328
2025-10-17 03:46:24 | epoch: 0023/100, training time: 75.8s, inference time: 2.2s
train loss: 2.2359, val_loss: 2.1597
2025-10-17 03:47:41 | epoch: 0024/100, training time: 75.6s, inference time: 2.2s
train loss: 2.2613, val_loss: 2.2114
2025-10-17 03:49:01 | epoch: 0025/100, training time: 77.9s, inference time: 2.2s
train loss: 2.2118, val_loss: 2.0447
val loss decrease from 2.0460 to 2.0447, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 03:50:20 | epoch: 0026/100, training time: 76.2s, inference time: 2.2s
train loss: 2.2004, val_loss: 2.0915
2025-10-17 03:51:37 | epoch: 0027/100, training time: 75.1s, inference time: 2.2s
train loss: 2.2364, val_loss: 2.0742
2025-10-17 03:52:56 | epoch: 0028/100, training time: 77.0s, inference time: 2.2s
train loss: 2.2402, val_loss: 2.0889
2025-10-17 03:54:15 | epoch: 0029/100, training time: 76.6s, inference time: 2.3s
train loss: 2.2232, val_loss: 2.1001
2025-10-17 03:55:34 | epoch: 0030/100, training time: 76.4s, inference time: 2.2s
train loss: 2.3228, val_loss: 3.5247
2025-10-17 03:56:52 | epoch: 0031/100, training time: 76.5s, inference time: 2.2s
train loss: 2.2871, val_loss: 2.0877
2025-10-17 03:58:08 | epoch: 0032/100, training time: 73.9s, inference time: 2.2s
train loss: 2.2551, val_loss: 2.0595
2025-10-17 03:59:28 | epoch: 0033/100, training time: 77.2s, inference time: 2.2s
train loss: 2.2121, val_loss: 2.1379
2025-10-17 04:00:44 | epoch: 0034/100, training time: 74.3s, inference time: 2.1s
train loss: 2.1931, val_loss: 2.0755
2025-10-17 04:02:05 | epoch: 0035/100, training time: 78.5s, inference time: 2.2s
train loss: 2.1796, val_loss: 2.0953
early stop at epoch: 0035
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8297, RMSE: 2.7856, MAPE: 6.30%
performance in each prediction step (train)
step 1: MAE=1.5533, RMSE=2.3096, MAPE=5.33%
step 2: MAE=1.8415, RMSE=2.7968, MAPE=6.33%
step 3: MAE=1.8600, RMSE=2.8381, MAPE=6.40%
step 4: MAE=1.8561, RMSE=2.8341, MAPE=6.39%
step 5: MAE=1.8586, RMSE=2.8396, MAPE=6.40%
step 6: MAE=1.8661, RMSE=2.8509, MAPE=6.42%
step 7: MAE=1.8842, RMSE=2.8803, MAPE=6.49%
step 8: MAE=1.9178, RMSE=2.9356, MAPE=6.62%
average: MAE=1.8297, RMSE=2.7856, MAPE=6.30%
val MAE: 2.0936, RMSE: 3.1998, MAPE: 7.21%
performance in each prediction step (val)
step 1: MAE=1.6820, RMSE=2.4816, MAPE=5.77%
step 2: MAE=2.0561, RMSE=3.1077, MAPE=7.07%
step 3: MAE=2.1268, RMSE=3.2526, MAPE=7.33%
step 4: MAE=2.1526, RMSE=3.3048, MAPE=7.42%
step 5: MAE=2.1675, RMSE=3.3398, MAPE=7.46%
step 6: MAE=2.1815, RMSE=3.3615, MAPE=7.51%
step 7: MAE=2.1884, RMSE=3.3736, MAPE=7.53%
step 8: MAE=2.1935, RMSE=3.3769, MAPE=7.55%
average: MAE=2.0936, RMSE=3.1998, MAPE=7.21%
test MAE: 2.1203, RMSE: 3.2307, MAPE: 7.27%
performance in each prediction step (test)
step 1: MAE=1.6999, RMSE=2.4964, MAPE=5.82%
step 2: MAE=2.0892, RMSE=3.1673, MAPE=7.15%
step 3: MAE=2.1595, RMSE=3.3016, MAPE=7.40%
step 4: MAE=2.1811, RMSE=3.3380, MAPE=7.47%
step 5: MAE=2.1934, RMSE=3.3590, MAPE=7.52%
step 6: MAE=2.2034, RMSE=3.3774, MAPE=7.56%
step 7: MAE=2.2121, RMSE=3.3939, MAPE=7.60%
step 8: MAE=2.2236, RMSE=3.4124, MAPE=7.64%
average: MAE=2.1203, RMSE=3.2307, MAPE=7.27%
total testing time: 22.8s
total time: 47.0min
