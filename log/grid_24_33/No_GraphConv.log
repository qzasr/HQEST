time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/DeepWalk_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 4,544 parameters
  ├─ convs: 4,544 parameters
query_linear: 4,608 parameters
  ├─ convs: 4,608 parameters
nav_attention: 25,536 parameters
  ├─ W_q: 4,288 parameters
  ├─ W_k: 4,288 parameters
  ├─ W_v: 4,288 parameters
  ├─ mapping: 4,288 parameters
  ├─ fusion: 8,384 parameters
st_embedding: 21,824 parameters
  ├─ FC_se: 8,576 parameters
  ├─ FC_te: 13,248 parameters
encoder_blocks: 293,956 parameters
  ├─ 0: 146,978 parameters
  ├─ 1: 146,978 parameters
transform_attn: 17,152 parameters
  ├─ FC_q: 4,288 parameters
  ├─ FC_k: 4,288 parameters
  ├─ FC_v: 4,288 parameters
  ├─ FC: 4,288 parameters
decoder_blocks: 293,956 parameters
  ├─ 0: 146,978 parameters
  ├─ 1: 146,978 parameters
output_layer: 4,355 parameters
  ├─ convs: 4,355 parameters
trainable parameters: 665,940
**** training model ****
2025-10-17 02:34:53 | epoch: 0001/100, training time: 79.6s, inference time: 2.2s
train loss: 2.9334, val_loss: 2.3578
val loss decrease from inf to 2.3578, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:36:10 | epoch: 0002/100, training time: 74.7s, inference time: 2.4s
train loss: 2.5885, val_loss: 2.3677
2025-10-17 02:37:27 | epoch: 0003/100, training time: 75.2s, inference time: 2.3s
train loss: 2.5391, val_loss: 2.2461
val loss decrease from 2.3578 to 2.2461, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:38:40 | epoch: 0004/100, training time: 70.3s, inference time: 2.2s
train loss: 2.4648, val_loss: 2.2209
val loss decrease from 2.2461 to 2.2209, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:39:53 | epoch: 0005/100, training time: 71.2s, inference time: 2.2s
train loss: 2.4598, val_loss: 2.2461
2025-10-17 02:41:09 | epoch: 0006/100, training time: 73.9s, inference time: 2.1s
train loss: 2.4641, val_loss: 2.2522
2025-10-17 02:42:28 | epoch: 0007/100, training time: 77.0s, inference time: 2.2s
train loss: 2.4540, val_loss: 2.2282
2025-10-17 02:43:45 | epoch: 0008/100, training time: 74.6s, inference time: 2.3s
train loss: 2.4086, val_loss: 2.2358
2025-10-17 02:45:04 | epoch: 0009/100, training time: 76.8s, inference time: 2.2s
train loss: 2.3785, val_loss: 2.1607
val loss decrease from 2.2209 to 2.1607, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:46:20 | epoch: 0010/100, training time: 73.4s, inference time: 2.2s
train loss: 2.3856, val_loss: 2.1588
val loss decrease from 2.1607 to 2.1588, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:47:35 | epoch: 0011/100, training time: 73.1s, inference time: 2.2s
train loss: 2.3644, val_loss: 2.1702
2025-10-17 02:48:52 | epoch: 0012/100, training time: 74.8s, inference time: 2.4s
train loss: 2.3712, val_loss: 2.1870
2025-10-17 02:50:08 | epoch: 0013/100, training time: 73.4s, inference time: 2.3s
train loss: 2.3362, val_loss: 2.1823
2025-10-17 02:51:29 | epoch: 0014/100, training time: 78.1s, inference time: 2.3s
train loss: 2.3650, val_loss: 2.2628
2025-10-17 02:52:44 | epoch: 0015/100, training time: 72.7s, inference time: 2.1s
train loss: 2.3712, val_loss: 2.1553
val loss decrease from 2.1588 to 2.1553, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:54:00 | epoch: 0016/100, training time: 74.4s, inference time: 2.2s
train loss: 2.3411, val_loss: 2.2221
2025-10-17 02:55:20 | epoch: 0017/100, training time: 77.8s, inference time: 2.1s
train loss: 2.3398, val_loss: 2.1326
val loss decrease from 2.1553 to 2.1326, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:56:36 | epoch: 0018/100, training time: 73.5s, inference time: 2.3s
train loss: 2.3155, val_loss: 2.1270
val loss decrease from 2.1326 to 2.1270, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-17 02:58:00 | epoch: 0019/100, training time: 82.5s, inference time: 2.1s
train loss: 2.3187, val_loss: 2.2060
2025-10-17 02:59:14 | epoch: 0020/100, training time: 71.2s, inference time: 2.1s
train loss: 2.3040, val_loss: 2.1333
2025-10-17 03:00:31 | epoch: 0021/100, training time: 75.5s, inference time: 2.2s
train loss: 2.3145, val_loss: 2.2042
2025-10-17 03:01:50 | epoch: 0022/100, training time: 76.0s, inference time: 2.2s
train loss: 2.3038, val_loss: 2.1458
2025-10-17 03:03:04 | epoch: 0023/100, training time: 72.1s, inference time: 2.1s
train loss: 2.2882, val_loss: 2.1342
2025-10-17 03:04:17 | epoch: 0024/100, training time: 71.5s, inference time: 2.1s
train loss: 2.2979, val_loss: 2.1802
2025-10-17 03:05:28 | epoch: 0012/100, training time: 85.6s, inference time: 2.9s
train loss: 2.3707, val_loss: 2.1948
2025-10-17 03:06:57 | epoch: 0013/100, training time: 85.5s, inference time: 2.9s
train loss: 2.3416, val_loss: 2.1817
2025-10-17 03:07:29 | epoch: 0014/100, training time: 89.2s, inference time: 2.9s
train loss: 2.3677, val_loss: 2.3255
2025-10-17 03:09:01 | epoch: 0015/100, training time: 89.2s, inference time: 2.9s
train loss: 2.3714, val_loss: 2.1527
early stop at epoch: 0024
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.9584, RMSE: 3.0234, MAPE: 6.72%
performance in each prediction step (train)
step 1: MAE=1.6775, RMSE=2.5069, MAPE=5.73%
step 2: MAE=1.9352, RMSE=2.9634, MAPE=6.61%
step 3: MAE=1.9689, RMSE=3.0328, MAPE=6.74%
step 4: MAE=1.9762, RMSE=3.0570, MAPE=6.77%
step 5: MAE=1.9898, RMSE=3.0873, MAPE=6.83%
step 6: MAE=2.0091, RMSE=3.1235, MAPE=6.90%
step 7: MAE=2.0364, RMSE=3.1743, MAPE=7.01%
step 8: MAE=2.0737, RMSE=3.2418, MAPE=7.14%
average: MAE=1.9584, RMSE=3.0234, MAPE=6.72%
val MAE: 2.1786, RMSE: 3.3548, MAPE: 7.40%
performance in each prediction step (val)
step 1: MAE=1.8011, RMSE=2.6833, MAPE=6.12%
step 2: MAE=2.1145, RMSE=3.2181, MAPE=7.20%
step 3: MAE=2.1815, RMSE=3.3516, MAPE=7.43%
step 4: MAE=2.2132, RMSE=3.4208, MAPE=7.53%
step 5: MAE=2.2448, RMSE=3.4818, MAPE=7.63%
step 6: MAE=2.2688, RMSE=3.5273, MAPE=7.70%
step 7: MAE=2.2917, RMSE=3.5618, MAPE=7.77%
step 8: MAE=2.3134, RMSE=3.5938, MAPE=7.84%
average: MAE=2.1786, RMSE=3.3548, MAPE=7.40%
test MAE: 2.2423, RMSE: 3.6239, MAPE: 7.85%
performance in each prediction step (test)
step 1: MAE=1.8287, RMSE=2.8865, MAPE=6.51%
step 2: MAE=2.1599, RMSE=3.4680, MAPE=7.61%
step 3: MAE=2.2406, RMSE=3.6184, MAPE=7.87%
step 4: MAE=2.2795, RMSE=3.6952, MAPE=7.98%
step 5: MAE=2.3168, RMSE=3.7616, MAPE=8.08%
step 6: MAE=2.3454, RMSE=3.8108, MAPE=8.17%
step 7: MAE=2.3722, RMSE=3.8554, MAPE=8.25%
step 8: MAE=2.3953, RMSE=3.8954, MAPE=8.32%
average: MAE=2.2423, RMSE=3.6239, MAPE=7.85%
total testing time: 21.5s
total time: 31.6min
