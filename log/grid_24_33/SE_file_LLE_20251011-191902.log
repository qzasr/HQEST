time_slot=15, torch_seed=42, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/LLE_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row='24', col='33', model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
fourier_filter: 9 parameters
  ├─ distribution_correction: 8 parameters
traffic_linear: 4,544 parameters
  ├─ convs: 4,544 parameters
query_linear: 4,608 parameters
  ├─ convs: 4,608 parameters
nav_attention: 25,536 parameters
  ├─ W_q: 4,288 parameters
  ├─ W_k: 4,288 parameters
  ├─ W_v: 4,288 parameters
  ├─ mapping: 4,288 parameters
  ├─ fusion: 8,384 parameters
st_embedding: 21,824 parameters
  ├─ FC_se: 8,576 parameters
  ├─ FC_te: 13,248 parameters
encoder_blocks: 293,956 parameters
  ├─ 0: 146,978 parameters
  ├─ 1: 146,978 parameters
transform_attn: 17,152 parameters
  ├─ FC_q: 4,288 parameters
  ├─ FC_k: 4,288 parameters
  ├─ FC_v: 4,288 parameters
  ├─ FC: 4,288 parameters
decoder_blocks: 293,956 parameters
  ├─ 0: 146,978 parameters
  ├─ 1: 146,978 parameters
output_layer: 4,355 parameters
  ├─ convs: 4,355 parameters
trainable parameters: 665,940
**** training model ****
2025-10-11 19:21:08 | epoch: 0001/100, training time: 89.7s, inference time: 3.2s
train loss: 2.8397, val_loss: 2.3586
val loss decrease from inf to 2.3586, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:22:41 | epoch: 0002/100, training time: 89.7s, inference time: 3.1s
train loss: 2.5290, val_loss: 2.2062
val loss decrease from 2.3586 to 2.2062, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:24:15 | epoch: 0003/100, training time: 90.2s, inference time: 3.2s
train loss: 2.4782, val_loss: 2.1236
val loss decrease from 2.2062 to 2.1236, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:25:48 | epoch: 0004/100, training time: 89.9s, inference time: 3.1s
train loss: 2.4141, val_loss: 2.1786
2025-10-11 19:27:21 | epoch: 0005/100, training time: 89.5s, inference time: 3.3s
train loss: 2.4119, val_loss: 2.1191
val loss decrease from 2.1236 to 2.1191, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:28:55 | epoch: 0006/100, training time: 91.1s, inference time: 3.3s
train loss: 2.4147, val_loss: 2.0891
val loss decrease from 2.1191 to 2.0891, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:30:31 | epoch: 0007/100, training time: 92.7s, inference time: 3.2s
train loss: 2.4082, val_loss: 2.1378
2025-10-11 19:32:07 | epoch: 0008/100, training time: 92.8s, inference time: 3.2s
train loss: 2.3638, val_loss: 2.1577
2025-10-11 19:33:41 | epoch: 0009/100, training time: 91.4s, inference time: 3.2s
train loss: 2.3786, val_loss: 2.2073
2025-10-11 19:35:16 | epoch: 0010/100, training time: 91.2s, inference time: 3.2s
train loss: 2.3573, val_loss: 2.0804
val loss decrease from 2.0891 to 2.0804, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:36:49 | epoch: 0011/100, training time: 90.3s, inference time: 3.1s
train loss: 2.3268, val_loss: 2.0667
val loss decrease from 2.0804 to 2.0667, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:38:23 | epoch: 0012/100, training time: 90.9s, inference time: 3.1s
train loss: 2.3323, val_loss: 2.1113
2025-10-11 19:39:56 | epoch: 0013/100, training time: 90.0s, inference time: 3.1s
train loss: 2.2978, val_loss: 2.1109
2025-10-11 19:41:27 | epoch: 0014/100, training time: 87.8s, inference time: 3.0s
train loss: 2.3314, val_loss: 2.1006
2025-10-11 19:43:01 | epoch: 0015/100, training time: 90.8s, inference time: 3.1s
train loss: 2.3340, val_loss: 2.0938
2025-10-11 19:44:36 | epoch: 0016/100, training time: 91.7s, inference time: 3.1s
train loss: 2.3063, val_loss: 2.0971
2025-10-11 19:46:10 | epoch: 0017/100, training time: 91.0s, inference time: 3.1s
train loss: 2.3055, val_loss: 2.0597
val loss decrease from 2.0667 to 2.0597, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-10-11 19:47:45 | epoch: 0018/100, training time: 91.9s, inference time: 3.3s
train loss: 2.2828, val_loss: 2.0775
2025-10-11 19:49:20 | epoch: 0019/100, training time: 91.8s, inference time: 3.2s
train loss: 2.2852, val_loss: 2.0710
2025-10-11 19:50:59 | epoch: 0020/100, training time: 95.8s, inference time: 3.3s
train loss: 2.2726, val_loss: 2.0922
2025-10-11 19:52:35 | epoch: 0021/100, training time: 92.2s, inference time: 3.1s
train loss: 2.2852, val_loss: 2.0952
2025-10-11 19:54:09 | epoch: 0022/100, training time: 91.2s, inference time: 3.1s
train loss: 2.3251, val_loss: 2.9882
2025-10-11 19:55:42 | epoch: 0023/100, training time: 90.1s, inference time: 3.0s
train loss: 2.3119, val_loss: 3.3767
2025-10-11 19:57:15 | epoch: 0024/100, training time: 90.4s, inference time: 3.1s
train loss: 2.3208, val_loss: 2.1462
2025-10-11 19:58:48 | epoch: 0025/100, training time: 89.9s, inference time: 3.1s
train loss: 2.3183, val_loss: 2.1284
2025-10-11 20:00:22 | epoch: 0026/100, training time: 90.7s, inference time: 3.1s
train loss: 2.2610, val_loss: 2.0632
2025-10-11 20:01:56 | epoch: 0027/100, training time: 90.4s, inference time: 3.1s
train loss: 2.2410, val_loss: 2.1082
early stop at epoch: 0027
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.9109, RMSE: 2.9155, MAPE: 6.54%
performance in each prediction step (train)
step 1: MAE=1.6670, RMSE=2.4866, MAPE=5.61%
step 2: MAE=1.9119, RMSE=2.8994, MAPE=6.50%
step 3: MAE=1.9317, RMSE=2.9441, MAPE=6.60%
step 4: MAE=1.9349, RMSE=2.9570, MAPE=6.63%
step 5: MAE=1.9397, RMSE=2.9718, MAPE=6.65%
step 6: MAE=1.9479, RMSE=2.9889, MAPE=6.69%
step 7: MAE=1.9640, RMSE=3.0167, MAPE=6.75%
step 8: MAE=1.9898, RMSE=3.0592, MAPE=6.86%
average: MAE=1.9109, RMSE=2.9155, MAPE=6.54%
val MAE: 2.1079, RMSE: 3.2014, MAPE: 7.21%
performance in each prediction step (val)
step 1: MAE=1.7856, RMSE=2.6360, MAPE=6.00%
step 2: MAE=2.0873, RMSE=3.1369, MAPE=7.12%
step 3: MAE=2.1368, RMSE=3.2583, MAPE=7.33%
step 4: MAE=2.1533, RMSE=3.2915, MAPE=7.39%
step 5: MAE=2.1630, RMSE=3.3091, MAPE=7.42%
step 6: MAE=2.1720, RMSE=3.3203, MAPE=7.45%
step 7: MAE=2.1795, RMSE=3.3276, MAPE=7.47%
step 8: MAE=2.1859, RMSE=3.3311, MAPE=7.49%
average: MAE=2.1079, RMSE=3.2014, MAPE=7.21%
test MAE: 2.1446, RMSE: 3.2552, MAPE: 7.31%
performance in each prediction step (test)
step 1: MAE=1.8160, RMSE=2.6721, MAPE=6.08%
step 2: MAE=2.1202, RMSE=3.1863, MAPE=7.18%
step 3: MAE=2.1709, RMSE=3.2958, MAPE=7.40%
step 4: MAE=2.1911, RMSE=3.3402, MAPE=7.49%
step 5: MAE=2.2032, RMSE=3.3677, MAPE=7.54%
step 6: MAE=2.2090, RMSE=3.3807, MAPE=7.57%
step 7: MAE=2.2173, RMSE=3.3918, MAPE=7.60%
step 8: MAE=2.2290, RMSE=3.4069, MAPE=7.64%
average: MAE=2.1446, RMSE=3.2552, MAPE=7.31%
total testing time: 31.6s
total time: 43.4min
