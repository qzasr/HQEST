time_slot=15, torch_seed=42, num_link=123, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=29, patience=10, learning_rate=0.009, decay_epoch=16, bn_decay=0.1, drop=0.01, traffic_file='./data/Traffic_speed_(26, 31).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_26_31_id.txt', adj_file='./data/edge_list_grid_(26,31)_weight.txt', row='26', col='31', model_file='./save_model/grid_26_31/Model_GF_test.pkl', log_file='./log/grid_26_31/log_test', SE_FC_bn_decay=0.1, SE_FC_act1='relu', SE_FC_act2='none', SE_FC_drop=0.01, TE_FC_bn_decay=0.1, TE_FC_act1='relu', TE_FC_act2='none', TE_FC_drop=0.01, FFT_bn_decay=0.1, FFT_FC_act1='relu', FFT_FC_act2='none', FFT_FC_drop=0.01, SA_Q_bn_decay=0.1, SA_Q_act='relu', SA_Q_drop=0.01, SA_K_bn_decay=0.1, SA_K_act='relu', SA_K_drop=0.01, SA_V_bn_decay=0.1, SA_V_act='relu', SA_V_drop=0.01, SA_FC_bn_decay=0.1, SA_FC_act='relu', SA_FC_drop=0.01, GMF_bn_decay=0.1, AUX_aux_bn_decay=0.1, AUX_aux_act1='relu', AUX_aux_act2='none', AUX_aux_drop=0.01, AUX_main_bn_decay=0.1, AUX_main_act1='relu', AUX_main_act2='none', AUX_main_drop=0.01, AUX_sim_bn_decay=0.1, AUX_sim_act1='relu', AUX_sim_act2='sigmoid', AUX_sim_drop=0.01, AUX_attn_bn_decay=0.1, AUX_attn_act1='relu', AUX_attn_act2='none', AUX_attn_drop=0.01, AUX_fusion_bn_decay=0.1, AUX_fusion_act1='relu', AUX_fusion_act2='none', AUX_fusion_drop=0.01, AUX_bn_decay=0.1, TA_Q_bn_decay=0.1, TA_Q_act='relu', TA_Q_drop=0.01, TA_K_bn_decay=0.1, TA_K_act='relu', TA_K_drop=0.01, TA_V_bn_decay=0.1, TA_V_act='relu', TA_V_drop=0.01, TA_fusion_bn_decay=0.1, TA_fusion_act='relu', TA_fusion_drop=0.01, NAV_Q_bn_decay=0.1, NAV_Q_act='relu', NAV_Q_drop=0.01, NAV_K_bn_decay=0.1, NAV_K_act='relu', NAV_K_drop=0.01, NAV_V_bn_decay=0.1, NAV_V_act='relu', NAV_V_drop=0.01, NAV_MAP_bn_decay=0.1, NAV_MAP_act='relu', NAV_MAP_drop=0.01, NAV_FUSION_bn_decay=0.1, NAV_FUSION_act='relu', NAV_FUSION_drop=0.01, STB_spatial_fusion_bn_decay=0.1, STB_spatial_fusion_act='relu', STB_spatial_fusion_drop=0.01, STB_temporal_fusion_bn_decay=0.1, STB_temporal_fusion_act='relu', STB_temporal_fusion_drop=0.01, STB_final_fusion_bn_decay=0.1, STB_final_fusion_act='relu', STB_final_fusion_drop=0.01, STB_gate_bn_decay=0.1, STB_gate_act1='relu', STB_gate_act2='sigmoid', STB_gate_drop=0.01, TA_transform_Q_bn_decay=0.1, TA_transform_Q_act='relu', TA_transform_Q_drop=0.0, TA_transform_K_bn_decay=0.1, TA_transform_K_act='relu', TA_transform_K_drop=0.0, TA_transform_V_bn_decay=0.1, TA_transform_V_act='relu', TA_transform_V_drop=0.0, TA_transform_FC_bn_decay=0.1, TA_transform_FC_act='relu', TA_transform_FC_drop=0.0, Traffic_Linear_bn_decay=0.1, Traffic_Linear_FC_act1='relu', Traffic_Linear_FC_act2='none', Traffic_Linear_FC_drop=0.01, Query_Linear_bn_decay=0.1, Query_Linear_FC_act1='relu', Query_Linear_FC_act2='none', Query_Linear_FC_drop=0.01, Output_bn_decay=0.1, Output_FC_act1='relu', Output_FC_act2='none', Output_FC_drop=0.01
Using device: cuda:0
trainX: torch.Size([4084, 8, 123])		 trainY: torch.Size([4084, 8, 123])
valX:   torch.Size([571, 8, 123])		valY:   torch.Size([571, 8, 123])
testX:   torch.Size([1156, 8, 123])		testY:   torch.Size([1156, 8, 123])
mean:   35.5409		std:   12.9660
data loaded!
compiling model...
trainable parameters: 682,324
**** training model ****
2025-10-20 03:16:53 | epoch: 0001/29, training time: 94.8s, inference time: 3.4s
train loss: 2.9622, val_loss: 2.6716
val loss decrease from inf to 2.6716, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:18:27 | epoch: 0002/29, training time: 90.1s, inference time: 3.3s
train loss: 2.6287, val_loss: 2.5551
val loss decrease from 2.6716 to 2.5551, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:19:54 | epoch: 0003/29, training time: 84.4s, inference time: 3.3s
train loss: 2.5564, val_loss: 2.5702
2025-10-20 03:21:18 | epoch: 0004/29, training time: 80.7s, inference time: 3.2s
train loss: 2.4949, val_loss: 2.4397
val loss decrease from 2.5551 to 2.4397, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:22:40 | epoch: 0005/29, training time: 78.9s, inference time: 3.1s
train loss: 2.4690, val_loss: 2.4805
2025-10-20 03:24:04 | epoch: 0006/29, training time: 80.3s, inference time: 3.1s
train loss: 2.4503, val_loss: 2.4651
2025-10-20 03:25:36 | epoch: 0007/29, training time: 88.8s, inference time: 3.1s
train loss: 2.4272, val_loss: 2.4785
2025-10-20 03:27:11 | epoch: 0008/29, training time: 91.6s, inference time: 3.3s
train loss: 2.4144, val_loss: 2.4702
2025-10-20 03:28:46 | epoch: 0009/29, training time: 91.9s, inference time: 3.2s
train loss: 2.3912, val_loss: 2.3936
val loss decrease from 2.4397 to 2.3936, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:30:22 | epoch: 0010/29, training time: 93.2s, inference time: 3.4s
train loss: 2.3907, val_loss: 2.3976
2025-10-20 03:31:57 | epoch: 0011/29, training time: 91.5s, inference time: 3.4s
train loss: 2.3681, val_loss: 2.4089
2025-10-20 03:33:32 | epoch: 0012/29, training time: 91.2s, inference time: 3.2s
train loss: 2.3588, val_loss: 2.3747
val loss decrease from 2.3936 to 2.3747, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:35:05 | epoch: 0013/29, training time: 89.9s, inference time: 3.3s
train loss: 2.3461, val_loss: 2.3998
2025-10-20 03:36:47 | epoch: 0014/29, training time: 98.8s, inference time: 3.3s
train loss: 2.3342, val_loss: 2.3634
val loss decrease from 2.3747 to 2.3634, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:38:28 | epoch: 0015/29, training time: 97.5s, inference time: 4.0s
train loss: 2.3211, val_loss: 2.3747
2025-10-20 03:40:05 | epoch: 0016/29, training time: 93.3s, inference time: 3.4s
train loss: 2.3285, val_loss: 2.6477
2025-10-20 03:41:42 | epoch: 0017/29, training time: 93.0s, inference time: 3.3s
train loss: 2.3018, val_loss: 2.3845
2025-10-20 03:43:17 | epoch: 0018/29, training time: 91.8s, inference time: 3.3s
train loss: 2.2940, val_loss: 2.5670
2025-10-20 03:44:51 | epoch: 0019/29, training time: 91.3s, inference time: 3.3s
train loss: 2.2729, val_loss: 2.3406
val loss decrease from 2.3634 to 2.3406, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
2025-10-20 03:46:25 | epoch: 0020/29, training time: 90.2s, inference time: 3.2s
train loss: 2.2766, val_loss: 2.4949
2025-10-20 03:47:57 | epoch: 0021/29, training time: 89.2s, inference time: 3.2s
train loss: 2.2681, val_loss: 2.4004
2025-10-20 03:49:30 | epoch: 0022/29, training time: 89.5s, inference time: 3.2s
train loss: 2.2563, val_loss: 2.3944
2025-10-20 03:51:02 | epoch: 0023/29, training time: 89.1s, inference time: 3.1s
train loss: 2.2433, val_loss: 2.4270
2025-10-20 03:52:35 | epoch: 0024/29, training time: 89.8s, inference time: 3.3s
train loss: 2.2408, val_loss: 2.4972
2025-10-20 03:54:10 | epoch: 0025/29, training time: 91.7s, inference time: 3.3s
train loss: 2.2291, val_loss: 2.3796
2025-10-20 03:55:42 | epoch: 0026/29, training time: 88.0s, inference time: 3.3s
train loss: 2.2154, val_loss: 2.3651
2025-10-20 03:57:16 | epoch: 0027/29, training time: 90.7s, inference time: 3.3s
train loss: 2.2335, val_loss: 2.4716
2025-10-20 03:58:49 | epoch: 0028/29, training time: 90.1s, inference time: 2.9s
train loss: 2.2128, val_loss: 2.4000
2025-10-20 04:00:18 | epoch: 0029/29, training time: 86.6s, inference time: 3.2s
train loss: 2.2054, val_loss: 2.3381
val loss decrease from 2.3406 to 2.3381, saving model to ./save_model/grid_26_31/Model_GF_test.pkl
Training completed. Best model saved to ./save_model/grid_26_31/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_26_31/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 2.0096, RMSE: 3.3245, MAPE: 6.83%
performance in each prediction step (train)
step 1: MAE=1.6801, RMSE=2.6978, MAPE=5.55%
step 2: MAE=1.9945, RMSE=3.2778, MAPE=6.69%
step 3: MAE=2.0334, RMSE=3.3645, MAPE=6.89%
step 4: MAE=2.0414, RMSE=3.3867, MAPE=6.95%
step 5: MAE=2.0499, RMSE=3.4069, MAPE=7.00%
step 6: MAE=2.0627, RMSE=3.4360, MAPE=7.05%
step 7: MAE=2.0863, RMSE=3.4770, MAPE=7.15%
step 8: MAE=2.1282, RMSE=3.5497, MAPE=7.34%
average: MAE=2.0096, RMSE=3.3245, MAPE=6.83%
val MAE: 2.3392, RMSE: 4.0450, MAPE: 8.59%
performance in each prediction step (val)
step 1: MAE=1.8562, RMSE=3.1002, MAPE=6.37%
step 2: MAE=2.2712, RMSE=3.8746, MAPE=8.14%
step 3: MAE=2.3685, RMSE=4.0933, MAPE=8.68%
step 4: MAE=2.4131, RMSE=4.1919, MAPE=8.94%
step 5: MAE=2.4341, RMSE=4.2393, MAPE=9.06%
step 6: MAE=2.4437, RMSE=4.2594, MAPE=9.11%
step 7: MAE=2.4542, RMSE=4.2800, MAPE=9.17%
step 8: MAE=2.4723, RMSE=4.3215, MAPE=9.26%
average: MAE=2.3392, RMSE=4.0450, MAPE=8.59%
test MAE: 2.2826, RMSE: 3.8177, MAPE: 7.78%
performance in each prediction step (test)
step 1: MAE=1.7978, RMSE=2.9317, MAPE=5.88%
step 2: MAE=2.2162, RMSE=3.6158, MAPE=7.39%
step 3: MAE=2.3132, RMSE=3.8677, MAPE=7.82%
step 4: MAE=2.3259, RMSE=3.8928, MAPE=8.01%
step 5: MAE=2.3533, RMSE=3.9975, MAPE=8.13%
step 6: MAE=2.3893, RMSE=4.0252, MAPE=8.23%
step 7: MAE=2.4260, RMSE=4.0960, MAPE=8.33%
step 8: MAE=2.4390, RMSE=4.1150, MAPE=8.45%
average: MAE=2.2826, RMSE=3.8177, MAPE=7.78%
total testing time: 32.3s
total time: 46.0min
